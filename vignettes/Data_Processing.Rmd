---
title: "Data Processing"
output: html_document
---

```{r}
library(rgdal)
library(sf)
library(raster)
library(units)
library(dplyr)
library(tidyr)

#devtools::install_github("AdamWilsonLab/PointCloudViewer")
proj="+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"

```


# Overall Workflow

Agisoft

  * Import photos, build 3D model
  * Classify points
  * Identify recruits as polygons
  * Export to txt file of points

CloudCompare

  * Subsample points or use mesh vertices?
  * Edit -> Scalar Fields -> Export Coordinates to SF
  * Compute a gaussian smooth (Edit->Scalar Fields -> Gaussian Filter) of each dimension (x, y, and z) using the desired neighborhood (0.01, 0.1, etc.) for EACH dimension and each 'scale' (e.g. 0.0025, 0.01, 0.1, etc.)
  * Roughness
  * Compute Illumination (Plugins -> P.C.V.)
  * Edit -> Normals -> convert to -> Dip Dip Direction (slope and aspect)
  * Export to an ascii file and import into R.
  
R
* Import to R
* Compute the 3d angle from each point to 1) it's 'smoothed' point and 2) the normal vector for that point. 
* Compute the distance from each point to it's smoothed surface in 3d space 
* If the angle is greater than 90, make the distance negative (a "hole").  If less - it stays positive and is a 'hill'.      


```{r}
d=read.csv("data/Vertices.txt")
```


# Cloud Compare Command line

```{r, eval=F}

## define path to CloudCompare
cc="/Applications/CloudCompare.app/Contents/MacOS/CloudCompare"
preamble="-AUTO_SAVE OFF -NO_TIMESTAMP -O "

input="data/vertices.txt"
#processing=" -COORD_TO_SF X -CURV GAUSS 0.01 -CURV GAUSS 0.1 "
processing="-COORD_TO_SF X -GAUSS 0.01"
export="-C_EXPORT_FMT ASC -ADD_HEADER -ADD_PTS_COUNT -SAVE_CLOUDS"

cmd=paste(cc,preamble,input,processing,export)
cmd

system(cmd)
```

```{r}
#d2=read.csv("data/vertices_NORMS_REORIENTED_X_TO_SF.asc")
```


# Distance to Smooth
```{r}
d$dist=dist3D(d$X..X,d$Coord..X.smooth.0.01.,d$Y,d$Coord..Y.smooth.0.01.,d$Z,d$Coord..Z.smooth.0.01.)
```


# Angle to smooth
```{r}
d$angle=apply(d[,c("X..X","Y","Z",
                "Coord..X.smooth.0.01.",
                "Coord..Y.smooth.0.01.",
                "Coord..Z.smooth.0.01.",
                "Nx","Ny","Nz")],1,angle3D)
```

# Correct Sign of distance
```{r}
d$sign=ifelse(d$angle<90,-1,1)
d$dists=d$dist*d$sign
```

## Create spatial object

```{r}
d=d%>%
  st_as_sf(coords=1:3)%>%
  st_set_crs(proj)
```

## Merge with recruit data

```{r}

datadir="/Users/adamw/Documents/Work/advising/Angela/data/20180514_Data"

# union points and polygons
recruits1<-read_sf(datadir,"EcT1_3r_OcR_plg")%>% 
  st_set_crs(NA)%>%  # needed due to strange prj of the shapefile
  st_set_crs(proj)%>%  # assign UTM projection
  st_cast("MULTIPOLYGON") # close all the rings to make complete polygons

recruits2<-read_sf(datadir,"EcT1_3r_OcR_pnt")%>% 
  st_set_crs(NA)%>%  # needed due to strange prj of the shapefile
  st_set_crs(proj)%>%  # assign UTM projection
  st_buffer(0.001)%>%  # assign UTM projection
  st_cast("MULTIPOLYGON")%>% # close all the rings to make complete polygons
  st_zm(drop=F,what="Z") # add empty Z dimension to merge with polygons 

recruits=rbind(recruits1,recruits2)

```

# Subset and rename data

Select only the variables you want to use in the model.  This just simplifies the data and makes the names shorter.
```{r}

env=d%>%
  select(x=Coord..X,
         y=Coord..Y,
         z=Coord..Z,
         exposure=Illuminance..PCV.,
         rough_0.01=Roughness.0.01.,
         rough_0.1=Roughness.0.1.,
         dists=dists)%>%
  mutate(pres=0,
         taxa=NA)

```

# Merge points and polygons

```{r}
recruits_int=st_intersection(recruits,env)%>%
  mutate(pres=1)%>%
  rename(taxa=NAME)%>%
  group_by(FID,taxa)

obs=recruits_int%>%
  summarise(x=mean(x),
            y=mean(y),
            z=mean(z),
            exposure=min(exposure),
            rough_0.01=max(rough_0.01),
            rough_0.1=max(rough_0.1),
            dists=min(dists),
            pres=mean(pres))%>%
  st_cast("POINT")%>%
  select(-FID)

fulld=rbind(env,obs)

# add an 'id' column to uniquely identify each point.
fulld$id=1:nrow(fulld)
```

```{r}
save(fulld,file="data/model.Rdata")

```

